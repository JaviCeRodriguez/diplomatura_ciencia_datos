{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "turkish-walker",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejercicios semana 8 - Clasificación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "noted-rover",
   "metadata": {},
   "source": [
    "El objetivo de los ejercicios de esta semana es integrar lo que aprendimos de modelos para clasificación al flujo de trabajo que venimos desarrollando: separación de conjunto de entrenamiento y testeo; preparación de los datos; diseño de características (polinomiales); determinación de hiperparámetros a partir de validación cruzada; evaluación final con el conjunto de testeo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "center-coating",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funciones útiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "turkish-gather",
   "metadata": {},
   "source": [
    "Volvemos a definir las funciones que usamos para los notebooks de esta semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52437650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "def plot_clasi(x, t, ws, labels=[], xp=[-1,1], spines='zero',\n",
    "               equal=True, join_centers=False, margin=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot results of linear classification problems.\n",
    "    :param np.array x: Data matrix\n",
    "    :param np.array t: Label vector.\n",
    "    :param list or tuple ws: list with fitted paramter vector of models, one element per model\n",
    "    :param tuple xp: start and end x-coordinates of decision boundaries and\n",
    "                     margins.\n",
    "    :param str or None spines: whether the spines go through zero. If None,\n",
    "                               the default behaviour is used.\n",
    "    :param bool equal: whether to use equal axis aspect (default=True;\n",
    "                       recomended to see the parameter vector normal to\n",
    "                       boundary)\n",
    "    :param bool join_centers: whether to draw lines between classes centres.\n",
    "    :param None or tuple margin: tupler of booleans that define whether\n",
    "                                 to plot margin for each model being plotted.\n",
    "                                 If None, False for all models.\n",
    "    \"\"\"\n",
    "    assert len(labels) == len(ws) or len(labels) == 0\n",
    "\n",
    "    if margin is None:\n",
    "        margin = [False] * len(ws)\n",
    "    else:\n",
    "        margin = np.atleast_1d(margin)\n",
    "    assert len(margin) == len(ws)\n",
    "\n",
    "    if len(labels) == 0:\n",
    "        labels = np.arange(len(ws)).astype('str')\n",
    "\n",
    "    # Agregemos el vector al plot\n",
    "    fig = plt.figure(figsize=(9, 7))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    xc1 = x[t == np.unique(t).max()]\n",
    "    xc2 = x[t == np.unique(t).min()]\n",
    "\n",
    "    ax.plot(*xc1.T, 'or', mfc='None', label='C1')\n",
    "    ax.plot(*xc2.T, 'ob', mfc='None', label='C2')\n",
    "\n",
    "    for i, w in enumerate(ws):\n",
    "        # Separa el sesgo del resto de los pesos\n",
    "        thr = -w[0]\n",
    "        w = w[1:]\n",
    "        # Calcula la norma del vector\n",
    "        wnorm = np.sqrt(np.sum(w**2))\n",
    "\n",
    "        # Ploteo vector de pesos\n",
    "        ax.quiver(0, thr/w[1], w[0]/wnorm, w[1]/wnorm,\n",
    "                  color='C{}'.format(i+2), scale=10, label=labels[i],\n",
    "                  zorder=10)\n",
    "\n",
    "        # ploteo plano perpendicular\n",
    "        xp = np.array(xp)\n",
    "        yp = (thr - w[0]*xp)/w[1]\n",
    "\n",
    "        plt.plot(xp, yp, '-', color='C{}'.format(i+2))\n",
    "\n",
    "        # ploteo el margen (para SVC)\n",
    "        if margin[i]:\n",
    "            for marg in [-1, 1]:\n",
    "                ym = yp + marg/w[1]\n",
    "                plt.plot(xp, ym, ':', color='C{}'.format(i+2))\n",
    "\n",
    "    if join_centers:\n",
    "        # Ploteo línea que une centros de los conjuntos\n",
    "        mu1 = xc1.mean(axis=1)\n",
    "        mu2 = xc2.mean(axis=1)\n",
    "        ax.plot([mu1[0], mu2[0]], [mu1[1], mu2[1]], 'o:k', mfc='None', ms=10)\n",
    "\n",
    "    ax.legend(loc=0, fontsize=12)\n",
    "    if equal:\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    if spines is not None:\n",
    "        for a in ['left', 'bottom']:\n",
    "            ax.spines[a].set_position('zero')\n",
    "        for a in ['top', 'right']:\n",
    "            ax.spines[a].set_visible(False)\n",
    "\n",
    "    for k in kwargs:\n",
    "        print(k, kwargs[k])\n",
    "        getattr(ax, 'set_'+k)(kwargs[k])\n",
    "\n",
    "    return\n",
    "\n",
    "def plot_fundec(fitter, x, t):\n",
    "\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    xx, yy = np.meshgrid(np.linspace(x[:, 0].min()-1, x[:, 0].max()+1, 200),\n",
    "                            np.linspace(x[:, 1].min()-1, x[:, 1].max()+1, 200))\n",
    "\n",
    "    # evaluate decision function\n",
    "    try:\n",
    "        Z = fitter.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        vcenter = 0.5\n",
    "        name = 'Probabilidad'\n",
    "    except AttributeError:\n",
    "        Z = fitter.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        vcenter = 0.0\n",
    "        name = 'Función de decisión'\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # veamos la función de decisión y la frontera de decisión\n",
    "    mynorm = colors.TwoSlopeNorm(vmin=Z.min(), vmax=Z.max(), vcenter=vcenter)\n",
    "    pme = plt.pcolormesh(xx, yy, Z, cmap=plt.cm.RdBu_r, norm=mynorm, shading='auto')\n",
    "    plt.colorbar(label= name)\n",
    "\n",
    "    plt.contour(xx, yy, Z, [vcenter,], colors='0.5', zorder=1)\n",
    "    if name == 'Probabilidad':\n",
    "        plt.contour(xx, yy, Z, [vcenter - 0.45, vcenter + 0.45],\n",
    "                    colors='white', linestyles='dashed', zorder=1)\n",
    "\n",
    "    xc1 = x[t == np.unique(t.flatten()).max()]\n",
    "    xc2 = x[t == np.unique(t.flatten()).min()]\n",
    "\n",
    "    plt.plot(*xc1.T, 'or', mfc='None', label='C1')\n",
    "    plt.plot(*xc2.T, 'ob', mfc='None', label='C2')\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis('tight')\n",
    "\n",
    "    return pme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pharmaceutical-airfare",
   "metadata": {},
   "source": [
    "## Café con dos medialunas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "christian-raise",
   "metadata": {},
   "source": [
    "Vamos a trabajar con un conjunto de datos sintéticos que puede armarse con la función de `sklearn` llamada `make_moons`.\n",
    "\n",
    "Vamos a generar el dataset y visualizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "datos, t = make_moons(n_samples=500, noise=0.15, random_state=20230628)\n",
    "plot_clasi(datos, t, ws=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af9ecf63",
   "metadata": {},
   "source": [
    "Este conjunto tiene dos variables $(x_1, x_2)$, que están contenidas en la varible `datos` que recién definimos. Además, el conjunto está etiquetado (rojo o azul; 0 o 1), y el valor de la etiqueta está contenido en la variable `t` (de *target*). \n",
    "\n",
    "Como se pueden imaginar, este conjunto no es linealmente separable si usamos estas dos variables separar con un modelo lineal, pero podemos generar nuevas características a partir de estas con `PolynomialFeatures` e intentar separar el conjunto.\n",
    "\n",
    "Pero antes de eso vamos a separar el conjunto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c92ed231",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "  - Separen al conjunto de datos original (`datos`) en un conjunto de entrenamiento (80%) y otro de testeo (20%). Agreguen al nombre de las variables `_train` y `_test` para diferenciarlas. \n",
    "\n",
    "**Sugerencia**: verifiquen que los arreglos resultantes tienen el tamaño y forma que esperan mirando el atributo `shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection as ms\n",
    "\n",
    "datos_train, datos_test, t_train, t_test =ms.train_test_split(datos, t, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4461709f",
   "metadata": {},
   "source": [
    "Ahora empiezan las decisiones. Elijan un algoritmo (Perceptrón o Regresión Logística) y un tipo de penalización (L1 o L2) con el que vamos a trabajar en esta primera parte.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd52b8e0",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    " \n",
    "Preparen un pipeline que estandarice los datos, genere features polinomiales de algún grado (empecemos con `degree=2`) y los use para ajustar el modelo elegido con una dada constante de regularización.\n",
    "\n",
    "**Ayuda**: recuerden que para armar el pipeline, hay que dar una lista (es decir, `[ ... ]`) de tuplas (es decir `( ... )`) con el nombre de los pasos y la función o clase correspondiente.\n",
    "\n",
    "**Ayuda2**: recuerden que cuando se combina con features polinomiales hay que setear `fit_intercept=False` en el clasificador (a menos que usen `include_bias=False` en `PolynomialFeatures`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b619a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "\n",
    "mi_pipe = Pipeline([('estandariza', StandardScaler()),\n",
    "                    ('poly', PolynomialFeatures(degree=3)),\n",
    "                    ('clasi', LogisticRegression(fit_intercept=False,\n",
    "                                                 penalty='l2',\n",
    "                                                 C=1.0))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8e72e78",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Ajusten los parámetros del clasificador usando el pipeline del paso anterior con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_pipe.fit(datos_train, t_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "825dbd81",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Impriman en pantalla los coeficientes encontrados. Recuerden que pueden acceder a cada paso del pipeline como si fuera un diccionario de python. P.ej., si llamé `'clasi'` al último paso, puedo usar `mi_pipe['clasi']` para acceder al clasificador.\n",
    "\n",
    "Respondan: ¿cuántos coeficientes hay? ¿tiene sentido con la cantidad de grados elegido para el PolynomialFeatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_pipe['clasi'].coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ad05d0e",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Usen la función `plot_fundec` para ver la frontera de decisión. \n",
    "    \n",
    "Evalúen si el grado del polinomio es el adecuado. Si no, súbanlo o bájenlo hasta encontrar algo que a ojo les resulte que funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fundec(mi_pipe, datos_train, t_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c21db5b0",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "\n",
    "Evalúen el desempeño del algoritmo en base a sus métricas de exactitud, precisión y exhaustividad. También calculen la matriz de pérdida (todo en el conjunto de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485904fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as m\n",
    "\n",
    "probas = mi_pipe.predict_proba(datos_train)\n",
    "\n",
    "umbrales = [0.5,]\n",
    "\n",
    "for umbral in umbrales:\n",
    "    y1 = np.where(probas[:, 1] >= umbral, 1, 0)\n",
    "\n",
    "    print('Umbral {}'.format(umbral))\n",
    "    print('----')\n",
    "    print('Exactitud: {:.3f}'.format(m.accuracy_score(t_train, y1)))\n",
    "    print('Precisión: {:.3f}'.format(m.precision_score(t_train, y1)))\n",
    "    print('Exhaustividad: {:.3f}'.format(m.recall_score(t_train, y1)))\n",
    "    print('f1 score: {:.3f}'.format(m.f1_score(t_train, y1)))\n",
    "    print('####')\n",
    "\n",
    "    print('Matriz de confusión')\n",
    "    print(m.confusion_matrix(t_train, y1))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3db7b93",
   "metadata": {},
   "source": [
    "## Ejercicio 7 \n",
    "\n",
    "Usar `GridSearchCV` para buscar valores óptimos de los hiperparámetros: grado de la transformación polinomial (`degree`) y constante de regularización (`C` o `alpha`, según qué modelo hayan elegido). ¿Cuáles son los mejores parámetros?\n",
    "\n",
    "**Recordatorio**. Cuando se usa `GridSearchCV` con un pipeline, el nombre de los parámetros hay que escribirlos como 'NOMBREDELPASO__NOMBREDELPARAMETRO'. Por ejemplo, para el paso de transformación polinomial, el grado es `poly__degree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mi_grilla =GridSearchCV(mi_pipe,\n",
    "                        param_grid = {'poly__degree': [3, 4, 5, 6, 7],\n",
    "                                      'clasi__C': np.logspace(0, 3, 10)},\n",
    "                        cv=5, scoring='neg_log_loss', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d764dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_grilla.fit(datos_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6deb702",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_grilla.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "201562aa",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "\n",
    "Usar `plot_fundec` con el mejor estimador obtenido a partir de la búsqueda. Calcular las métricas de arriba, pero esta vez usando `cross_val_predict` para obtener las predicciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fundec(mi_grilla.best_estimator_, datos_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a72a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "mejor_estimador = mi_grilla.best_estimator_\n",
    "\n",
    "y1 = cross_val_predict(mejor_estimador, datos_train, t_train)\n",
    "\n",
    "umbrales = [0.5,]\n",
    "\n",
    "for umbral in umbrales:\n",
    "\n",
    "    print('Umbral {}'.format(umbral))\n",
    "    print('----')\n",
    "    print('Exactitud: {:.3f}'.format(m.accuracy_score(t_train, y1)))\n",
    "    print('Precisión: {:.3f}'.format(m.precision_score(t_train, y1)))\n",
    "    print('Exhaustividad: {:.3f}'.format(m.recall_score(t_train, y1)))\n",
    "    print('f1 score: {:.3f}'.format(m.f1_score(t_train, y1)))\n",
    "    print('####')\n",
    "\n",
    "    print('Matriz de confusión')\n",
    "    print(m.confusion_matrix(t_train, y1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f28196f",
   "metadata": {},
   "source": [
    "## Ejercicio 9\n",
    "\n",
    "Evalúen ahora el algoritmo tuneado en el conjunto de testeo. Comparen con los resultados del ejericio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673853ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_estimador = mi_grilla.best_estimator_\n",
    "\n",
    "y1 = mejor_estimador.predict(datos_test)\n",
    "\n",
    "umbrales = [0.5,]\n",
    "\n",
    "for umbral in umbrales:\n",
    "\n",
    "    print('Umbral {}'.format(umbral))\n",
    "    print('----')\n",
    "    print('Exactitud: {:.3f}'.format(m.accuracy_score(t_test, y1)))\n",
    "    print('Precisión: {:.3f}'.format(m.precision_score(t_test, y1)))\n",
    "    print('Exhaustividad: {:.3f}'.format(m.recall_score(t_test, y1)))\n",
    "    print('f1 score: {:.3f}'.format(m.f1_score(t_test, y1)))\n",
    "    print('####')\n",
    "\n",
    "    print('Matriz de confusión')\n",
    "    print(m.confusion_matrix(t_test, y1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4886fbcf",
   "metadata": {},
   "source": [
    "## Mismo con el perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669fc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_pipe_perce = Pipeline([('estandariza', StandardScaler()),\n",
    "                       ('poly', PolynomialFeatures(degree=3)),\n",
    "                        ('clasi', Perceptron(fit_intercept=False,\n",
    "                                                     penalty='l2',\n",
    "                                                     alpha=1.0))])\n",
    "\n",
    "mi_grilla_perce =GridSearchCV(mi_pipe_perce,\n",
    "                              param_grid = {'poly__degree': [3, 4, 5, 6, 7],\n",
    "                                            'clasi__alpha': np.logspace(-3, 0, 10)},\n",
    "                              cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ed423",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_grilla_perce.fit(datos_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_grilla_perce.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b83e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fundec(mi_grilla_perce.best_estimator_, datos_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_estimador = mi_grilla_perce.best_estimator_\n",
    "\n",
    "y1 = cross_val_predict(mejor_estimador, datos_train, t_train)\n",
    "\n",
    "umbrales = [0.5,]\n",
    "\n",
    "for umbral in umbrales:\n",
    "\n",
    "    print('Umbral {}'.format(umbral))\n",
    "    print('----')\n",
    "    print('Exactitud: {:.3f}'.format(m.accuracy_score(t_train, y1)))\n",
    "    print('Precisión: {:.3f}'.format(m.precision_score(t_train, y1)))\n",
    "    print('Exhaustividad: {:.3f}'.format(m.recall_score(t_train, y1)))\n",
    "    print('f1 score: {:.3f}'.format(m.f1_score(t_train, y1)))\n",
    "    print('####')\n",
    "\n",
    "    print('Matriz de confusión')\n",
    "    print(m.confusion_matrix(t_train, y1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-mac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-showcode": false,
  "vscode": {
   "interpreter": {
    "hash": "2b7aa682480b82eb27ca7b5ecfebdb0027bb2a276e6bdff64c1ddeab03557e9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

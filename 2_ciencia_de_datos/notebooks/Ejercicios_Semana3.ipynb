{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1: Reducción de dimensionalidad ##\n",
        "\n",
        "Es este ejercicio vamos a trabajar con los datasets que ya usamos anteiormente de medidas de personas del ejército de EEUU `ansurMen.csv` y `ansurMen.csv`."
      ],
      "metadata": {
        "id": "prGVkzsBqmVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a)** Carguen los dos csvs en dos dataframes distintos de pandas. Agréguenle a cada uno una nueva columna 'SEXO' que tenga los valores 'H' y 'M', según corresponda, para poder identificar de qué dataset vino cada persona. Luego unan los dos datasets en uno nuevo usando la función de pandas `pd.concat([df1, df2])`."
      ],
      "metadata": {
        "id": "V_O_4bVAODbL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSsNrHZTVsiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b)** Definan un nuevo dataframe de variables sólo numéricas a partir del anterior, descartando las columnas 'SEXO' y 'SUBJECT_NUMBER' (¿tiene sentido quedarse con esta última columna?). Luego apliquenle el `StandardScaler` de `sklearn` a este nuevo dataframe, y hagan una reducción dimensional usando PCA. ¿Con cuántas componentes necesito quedarme para explicar el 95% de la varianza de los datos?"
      ],
      "metadata": {
        "id": "-urojOMXPTzy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bgKon5-uVszn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c)** Ahora hagan otro PCA, pero quedándose sólo con 2 componentes, y hagan un scatterplot de los datos. ¿Qué es lo que se ve? Traten de pintar los puntos usando la columna categórica \"SEXO\" que tiene el dataset original.  "
      ],
      "metadata": {
        "id": "T-wpFD4IRozX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHz2h6GQVtQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d) (Opcional)**. Ahora hagan un PCA con un número reducido de componentes (digamos 8), y luego apliquen un TSNE con 2 componentes. Grafiquen los resultados cómo hicieron en el punto anterior. ¿Qué se ve ahora? Pueden jugar con el número de componentes del PCA, o sólo hacer TSNE, y ver las diferencias.  "
      ],
      "metadata": {
        "id": "3jvcJy5uSZT0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93-VXnEzVunY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2: Preprocesamiento ##\n",
        "\n",
        "En este ejercico vamos a trabajar con un dataset bastante problemático: el dataset de arbolado en calles de CABA, [arbolado-publico-lineal-2017-2018.csv](https://drive.google.com/file/d/1tCbEg1Yy0xgmY5e3hMgbOGYEiJ9Ffw8P/view?usp=sharing) (extraído de [aquí](https://data.buenosaires.gob.ar/dataset/arbolado-publico-lineal)). El mismo el similar al de árboles en parques que ya hemos usado, pero tiene bastantes más registros."
      ],
      "metadata": {
        "id": "JDrgJTXgq-Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Cargando los datos**. Importen este nuevo dataset usando pandas. Van a notar que les da una advertencia (*warning*) porque hay algunas columnas con tipos mezclados. Por ahora ignorenlo. \n",
        "\n",
        "Para ahorrarnos trabajo, definan un nuevo DataFrame usando solo las columnas `['nro_registro', 'nombre_cientifico', 'estado_plantera', 'ubicacion_plantera', 'nivel_plantera', 'diametro_altura_pecho', 'altura_arbol']`."
      ],
      "metadata": {
        "id": "d65eq26a8SJw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "caE1pg5vVwIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Limpieza de datos (I)**. Analicen los valores únicos que pueden tomar las columnas 'estado_plantera', 'ubicacion_plantera' y 'nivel_plantera'. ¿Qué es lo que ven?\n",
        "\n",
        "Para las tres columnas, unifiquen los valores que pertecen a una misma catgoría."
      ],
      "metadata": {
        "id": "Ps1qPkfN_5EO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FI-gVKVBVxWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) Limpieza de datos (II)**. Hagan histogramas de los valores de las variables 'diametro_altura_pecho' y 'altura_arbol'.\n",
        "\n",
        "A primera vista no parece haber nada raro, pero fijense que para el diámetro (que está medido en cm) hay muchos datos con valor 0 (pueden usar el método `value_counts()`). Si bien podría haber árboles con menos de 1 cm de diámetro, la cantidad de los mismos nos hace sospechar que en gran parte de los casos se trata de un error.\n",
        "\n",
        "Eliminen las filas con diámetro 0, o al menos por ahora reemplacen el valor por `nan`."
      ],
      "metadata": {
        "id": "JWd5xkxlBPDN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MvZ95ElIVymZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d) Datos faltantes**. Analicen la cantidad de datos faltantes en cada columna y decidan qué hacer con ellos (descartarlos, crear una nueva categoría en las variables categóricas, reemplazarla por promedio/mediana en las numéricas, etc.)"
      ],
      "metadata": {
        "id": "y2cmEq6qHvN8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VBFMz4rVz5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e) Variables categóricas**. Apliquen el método de One-Hot Encoding a alguna de las variables categóricas del dataset. ¿De qué va a depender la cantidad de componentes de los vectores resultantes?"
      ],
      "metadata": {
        "id": "_ZBJj9AxMxVV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RCdSsUroMx46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
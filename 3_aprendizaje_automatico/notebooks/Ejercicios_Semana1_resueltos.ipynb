{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "turkish-walker",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejercicios semana 1 - Árboles de Decisión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "noted-rover",
   "metadata": {},
   "source": [
    "El objetivo de los ejercicios de esta semana es integrar lo que aprendimos de modelos de árboles de decisión en un caso donde la frontera de decisión es compleja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab125513",
   "metadata": {},
   "source": [
    "## Hagamos lunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b388e7e",
   "metadata": {},
   "source": [
    "Vamos a utilizar una función que nos va a acompañar durante las próximas clases. Esta función sirve para generar un dataset sintético más o menos complicado (pero en pocas dimensiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00379aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = make_moons(n_samples=200, noise=0.15, random_state=42)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea3970b",
   "metadata": {},
   "source": [
    "1. Entrenar un DecisionTreeClassifier con estos datos, usando como hiperparámetros valores elegidos a mano (cambien `max_depth` y dos hiperámetros más a elección)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f195451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=3, min_samples_split=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb4fb5",
   "metadata": {},
   "source": [
    "2. Evaluar el resultado con validación cruzada, usando como métrica la exactitud (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933be4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt, X, t, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Exactitud = {:.2f} +/- {:.2f}'.format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0b4c6",
   "metadata": {},
   "source": [
    "3. Usar GridSearchCV o RandomizedSearchCV para encontrar los mejores valores de los hiperparámetros elegidos (y `max_depth`). **Ayuda**: pueden usar `n_jobs=-1` para usar todos los procesadores que tengan disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ada03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_dt = GridSearchCV(dt, param_grid={'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                     'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "                                     'min_impurity_decrease': [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5]},\n",
    "                     cv=5, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt.fit(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa675a8",
   "metadata": {},
   "source": [
    "4. Impriman en pantalla el valor de los mejores parámetros y el valor del score para estos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Los mejores parámetros son', gs_dt.best_params_)\n",
    "print('El mejor score es {:.2f}'.format(gs_dt.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88821eca",
   "metadata": {},
   "source": [
    "5. Graficar la frontera de decisión usando el código `plot_decision_boundary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función adaptada de A. Gèron\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, t, axes=[0, 7.5, 0, 3], is_iris=True,\n",
    "                           legend=False, plot_training=True, ngridpoints=200,\n",
    "                           alpha=1.0, ax=None):\n",
    "\n",
    "    # Prepara los arreglos para colorear\n",
    "    x1s = np.linspace(axes[0], axes[1], ngridpoints)\n",
    "    x2s = np.linspace(axes[2], axes[3], ngridpoints)\n",
    "\n",
    "    # los convierte en una grilla\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "\n",
    "    # Calcula las predicciones sobre la grilla\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.figure().add_subplot(111)\n",
    "\n",
    "    # Grafica con colores esa grilla\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    ax.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "\n",
    "    if not is_iris:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if plot_training:\n",
    "        sct = ax.scatter(X[:,0], X[:, 1], c=t, edgecolors='k', s=9**2,\n",
    "                  cmap=plt.cm.rainbow, alpha=alpha)\n",
    "\n",
    "        # plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
    "        # plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
    "        # plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris virginica\")\n",
    "        # plt.axis(axes)\n",
    "    if is_iris:\n",
    "        legend1 = ax.legend(sct.legend_elements()[0], iris.target_names,\n",
    "                            loc=\"upper left\", title=\"Clases\")\n",
    "        ax.add_artist(legend1)\n",
    "\n",
    "        ax.set_xlabel(\"Largo del pétalo\", fontsize=16)\n",
    "        ax.set_ylabel(\"Ancho del pétalo\", fontsize=16)\n",
    "    else:\n",
    "        ax.set_xlabel(r\"$x_1$\", fontsize=18)\n",
    "        ax.set_ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
    "    if legend:\n",
    "        ax.legend(loc=\"lower right\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_decision_boundary(gs_dt, X, t, \n",
    "                       alpha=0.5, is_iris=False,\n",
    "                       axes=[-1.5, 3, -2.5, 2.0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7816e1",
   "metadata": {},
   "source": [
    "6. Cambiar los valores del ruido y cantidad de puntos en la función que genera los datos y ver la dependencia de la calidad del estimador frente a esos parámetros adicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32765415",
   "metadata": {},
   "source": [
    "### Aumentemos primero el ruido de los datos, sin cambiar la cantidad de puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar los datos nuevos, con más ruido y datos\n",
    "X, t = make_moons(n_samples=200, noise=0.3, random_state=42)\n",
    "plt.scatter(X[:,0], X[:,1], c=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39aec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar DT\n",
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=3, min_samples_split=5)\n",
    "\n",
    "# Ajuste de los hiperparámetros \n",
    "gs_dt = GridSearchCV(dt, param_grid={'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                     'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "                                     'min_impurity_decrease': [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5]},\n",
    "                     cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "gs_dt.fit(X, t)\n",
    "\n",
    "# \n",
    "print('Los mejores parámetros son', gs_dt.best_params_)\n",
    "print('El mejor score es {:.2f}'.format(gs_dt.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe233d8b",
   "metadata": {},
   "source": [
    "El nuevo árbol tiene más profundidad, es decir que es más flexible, y un número mínimo de nodos en las hojas ligeramente menor. Es decir, es más flexible.\n",
    "\n",
    "El `score` cae significativamente, como es de esperar frente al aumento de ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_decision_boundary(gs_dt, X, t, \n",
    "                       alpha=0.5, is_iris=False,\n",
    "                       axes=[-2.5, 3.5, -1.5, 2.0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccafe79",
   "metadata": {},
   "source": [
    "### Aumentemos la cantidad de puntos dejando el ruido fijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbc029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar los datos nuevos, con más ruido y datos\n",
    "X, t = make_moons(n_samples=500, noise=0.15, random_state=42)\n",
    "plt.scatter(X[:,0], X[:,1], c=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3426cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar DT\n",
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=3, min_samples_split=5)\n",
    "\n",
    "# Ajuste de los hiperparámetros \n",
    "gs_dt = GridSearchCV(dt, param_grid={'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                                     'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "                                     'min_impurity_decrease': [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5]},\n",
    "                     cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "gs_dt.fit(X, t)\n",
    "\n",
    "# \n",
    "print('Los mejores parámetros son', gs_dt.best_params_)\n",
    "print('El mejor score es {:.2f}'.format(gs_dt.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a222a",
   "metadata": {},
   "source": [
    "El nuevo árbol tiene ligeramente más profundidad, y de nuevo un número mínimo de nodos en las hojas ligeramente menor. Es decir, en este caso también es más flexible.\n",
    "\n",
    "Pero en este caso, el `score` mejora significativamente, como es de esperar frente al aumento de datos (con error fijo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e37212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_decision_boundary(gs_dt, X, t, \n",
    "                       alpha=0.5, is_iris=False,\n",
    "                       axes=[-1.5, 2.5, -1.5, 2.0])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-mac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-showcode": false,
  "vscode": {
   "interpreter": {
    "hash": "2b7aa682480b82eb27ca7b5ecfebdb0027bb2a276e6bdff64c1ddeab03557e9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
